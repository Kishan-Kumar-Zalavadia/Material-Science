{"cells":[{"cell_type":"markdown","metadata":{"id":"Wi7cregFtUVx"},"source":["# Remove entries that do not have composition and remove the element weights."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"cBcVCHtOrsd1","executionInfo":{"status":"ok","timestamp":1730141568354,"user_tz":300,"elapsed":205,"user":{"displayName":"Kishan kumar","userId":"12369662999305954818"}}},"outputs":[],"source":["import json\n","\n","# List of valid periodic table elements\n","periodic_table_elements = {\n","    \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\",\n","    \"Cl\", \"Ar\", \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"Ga\",\n","    \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\",\n","    \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\", \"Pm\",\n","    \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\",\n","    \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\", \"Pa\",\n","    \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\", \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\",\n","    \"Bh\", \"Hs\", \"Mt\", \"Ds\", \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n","}\n","\n","# Function to process the JSON data\n","def process_data(input_file, output_file):\n","    with open(input_file, 'r') as infile:\n","        data = json.load(infile)\n","\n","    # Create a list to hold filtered data\n","    filtered_data = []\n","\n","    # Process each entity\n","    for entity in data:\n","        composition = entity.get('composition')\n","        if composition:\n","            # Filter out elements not in the periodic table\n","            valid_elements = [elem for elem in composition.keys() if elem in periodic_table_elements]\n","            if valid_elements:\n","                # Update composition with only element names\n","                entity['composition'] = valid_elements\n","                filtered_data.append(entity)\n","\n","    # Write the updated data to a new JSON file\n","    with open(output_file, 'w') as outfile:\n","        json.dump(filtered_data, outfile, indent=4)\n","\n","# Usage example\n","input_file = 'allData_result.json'\n","output_file = 'filtered_allData_result.json'\n","process_data(input_file, output_file)\n"]},{"cell_type":"markdown","metadata":{"id":"CUlo7-jfxIrN"},"source":["# Train model"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155652,"status":"ok","timestamp":1730141724186,"user":{"displayName":"Kishan kumar","userId":"12369662999305954818"},"user_tz":300},"id":"uqAFpckNwFPY","outputId":"3021f34a-db74-420d-ee52-c00c2777e5f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cross-validation accuracy for RandomForest: 71.00%\n","Test accuracy for RandomForest: 50.00%\n","\n","Test Results (Original vs Predicted):\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['H', 'Si', 'Cr', 'Mn', 'Fe', 'Co'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Cu', 'Zn'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Si', 'Cr', 'Mn', 'Fe', 'Co', 'Cu'] | Predicted: ['Si', 'Cr', 'Mn', 'Fe', 'Co', 'Cu']\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","\n","==================================================\n","\n","Skipping SVM due to error: The number of classes has to be greater than one; got 1 class\n"]}],"source":["import json\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","# Load filtered JSON data\n","def load_data(input_file):\n","    with open(input_file, 'r') as infile:\n","        data = json.load(infile)\n","    return data\n","\n","# Preprocessing the data\n","def preprocess_data(data, periodic_table_elements):\n","    compositions = []\n","    features = []\n","\n","    # Extract features and compositions\n","    for entry in data:\n","        # Using lemma as features (just an example)\n","        features.append(entry['lemma'])\n","        # Create binary composition array (1 if element exists, 0 otherwise)\n","        composition = [1 if elem in entry['composition'] else 0 for elem in periodic_table_elements]\n","        compositions.append(composition)\n","\n","    return features, compositions\n","\n","# Encode the feature list into a one-hot encoding format\n","def encode_features(feature_list):\n","    # Create a DataFrame and use get_dummies for one-hot encoding\n","    df = pd.DataFrame(feature_list)\n","    df_encoded = pd.get_dummies(df, prefix_sep='_', drop_first=True)\n","    return df_encoded\n","\n","# Train and evaluate model\n","def train_and_evaluate(X, y, periodic_table_elements):\n","    # Split the data into 80% training and 20% testing\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Use Random Forest and SVM as models with MultiOutputClassifier for multi-label classification\n","    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","    svm_model = SVC(kernel='linear', class_weight='balanced')  # Adding class_weight='balanced' to handle imbalance\n","\n","    classifiers = {\n","        'RandomForest': MultiOutputClassifier(rf_model),\n","        'SVM': MultiOutputClassifier(svm_model, n_jobs=-1)\n","    }\n","\n","    # Train and cross-validate models\n","    for name, model in classifiers.items():\n","        try:\n","            model.fit(X_train, y_train)\n","        except ValueError as e:\n","            print(f\"Skipping {name} due to error: {e}\")\n","            continue\n","\n","        # Cross-validation with 5 folds\n","        try:\n","            cross_val_scores = cross_val_score(model, X_train, y_train, cv=5)\n","            print(f\"Cross-validation accuracy for {name}: {cross_val_scores.mean() * 100:.2f}%\")\n","        except ValueError as e:\n","            print(f\"Cross-validation failed for {name} due to error: {e}\")\n","            continue\n","\n","        # Make predictions on the test set\n","        y_pred = model.predict(X_test)\n","\n","        # Calculate accuracy\n","        accuracy = accuracy_score(y_test, y_pred)\n","        print(f\"Test accuracy for {name}: {accuracy * 100:.2f}%\")\n","\n","        # Print original and predicted composition for test set\n","        print(\"\\nTest Results (Original vs Predicted):\")\n","        for i in range(len(y_test)):\n","            original = [periodic_table_elements[idx] for idx, val in enumerate(y_test[i]) if val == 1]\n","            predicted = [periodic_table_elements[idx] for idx, val in enumerate(y_pred[i]) if val == 1]\n","            print(f\"Original: {original} | Predicted: {predicted}\")\n","        print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# Main function to run the process\n","def main():\n","    input_file = 'filtered_allData_result.json'\n","\n","    # List of valid periodic table elements (assuming the same as in previous code)\n","    periodic_table_elements = [\n","        \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\",\n","        \"Cl\", \"Ar\", \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"Ga\",\n","        \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\",\n","        \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\", \"Pm\",\n","        \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\",\n","        \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\", \"Pa\",\n","        \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\", \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\",\n","        \"Bh\", \"Hs\", \"Mt\", \"Ds\", \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n","    ]\n","\n","    # Load and preprocess data\n","    data = load_data(input_file)\n","    features, compositions = preprocess_data(data, periodic_table_elements)\n","\n","    # Encode features into a numeric format\n","    X = encode_features(features)\n","    y = np.array(compositions)\n","\n","    # Train and evaluate models\n","    train_and_evaluate(X, y, periodic_table_elements)\n","\n","# Run the script\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"markdown","metadata":{"id":"sTmYTsBcxFYh"},"source":["# Improve accuracy"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRzgMmX_xE5Q","executionInfo":{"status":"ok","timestamp":1730141922465,"user_tz":300,"elapsed":198283,"user":{"displayName":"Kishan kumar","userId":"12369662999305954818"}},"outputId":"9f99e9c3-11f1-4659-a3d8-f95d6926b5de"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Tuning RandomForest Hyperparameters...\n","\n","Fitting 2 folds for each of 54 candidates, totalling 108 fits\n","Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n","\n","Training RandomForest model...\n","\n","Cross-validation accuracy for RandomForest: 71.00%\n","Test accuracy for RandomForest: 33.33%\n","\n","Test Results (Original vs Predicted):\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['H', 'Si', 'Cr', 'Mn', 'Fe', 'Co'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","\n","==================================================\n","\n","\n","Training XGBoost model...\n","\n","Cross-validation accuracy for XGBoost: 32.00%\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:58:36] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:58:37] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:58:38] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:58:39] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:58:40] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:58:41] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Test accuracy for XGBoost: 33.33%\n","\n","Test Results (Original vs Predicted):\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['H', 'Si', 'Cr', 'Mn', 'Fe', 'Co'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","\n","==================================================\n","\n"]}],"source":["import json\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from xgboost import XGBClassifier\n","\n","# Load filtered JSON data\n","def load_data(input_file):\n","    with open(input_file, 'r') as infile:\n","        data = json.load(infile)\n","    return data\n","\n","# Preprocessing the data\n","def preprocess_data(data, periodic_table_elements):\n","    compositions = []\n","    features = []\n","\n","    # Extract features and compositions\n","    for entry in data:\n","        # Using lemma as features (just an example)\n","        features.append(entry['lemma'])\n","        # Create binary composition array (1 if element exists, 0 otherwise)\n","        composition = [1 if elem in entry['composition'] else 0 for elem in periodic_table_elements]\n","        compositions.append(composition)\n","\n","    return features, compositions\n","\n","# Encode the feature list into a one-hot encoding format\n","def encode_features(feature_list):\n","    # Create a DataFrame and use get_dummies for one-hot encoding\n","    df = pd.DataFrame(feature_list)\n","    df_encoded = pd.get_dummies(df, prefix_sep='_', drop_first=True)\n","    return df_encoded\n","\n","# Function for Hyperparameter tuning using GridSearchCV for RandomForest\n","def tune_hyperparameters(X_train, y_train):\n","    param_grid = {\n","        'n_estimators': [100, 200],\n","        'max_depth': [10, 20, None],\n","        'min_samples_split': [2, 5, 10],\n","        'min_samples_leaf': [1, 2, 4]\n","    }\n","    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=2, n_jobs=-1, verbose=2)\n","    grid_search.fit(X_train, y_train)\n","    print(\"Best Hyperparameters:\", grid_search.best_params_)\n","    return grid_search.best_estimator_\n","\n","# Train and evaluate model\n","def train_and_evaluate(X, y, periodic_table_elements):\n","    # Split the data into 80% training and 20% testing\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","    # Feature Scaling (important for SVM, XGBoost, etc.)\n","    scaler = StandardScaler()\n","    X_train_scaled = scaler.fit_transform(X_train)\n","    X_test_scaled = scaler.transform(X_test)\n","\n","    # Tune RandomForest Hyperparameters\n","    print(\"\\nTuning RandomForest Hyperparameters...\\n\")\n","    rf_model = tune_hyperparameters(X_train_scaled, y_train)\n","\n","    # Models to evaluate\n","    models = {\n","        'RandomForest': MultiOutputClassifier(rf_model),\n","        'XGBoost': MultiOutputClassifier(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))\n","    }\n","\n","    # Cross-validation with K-Folds (since StratifiedKFold doesn't support multi-label)\n","    kf = KFold(n_splits=5)\n","\n","    for name, model in models.items():\n","        # Cross-validation\n","        print(f\"\\nTraining {name} model...\\n\")\n","        cross_val_scores = cross_val_score(model, X_train_scaled, y_train, cv=kf, n_jobs=-1)\n","        print(f\"Cross-validation accuracy for {name}: {cross_val_scores.mean() * 100:.2f}%\")\n","\n","        # Train the model on full training set\n","        model.fit(X_train_scaled, y_train)\n","\n","        # Make predictions on the test set\n","        y_pred = model.predict(X_test_scaled)\n","\n","        # Calculate accuracy\n","        accuracy = accuracy_score(y_test, y_pred)\n","        print(f\"Test accuracy for {name}: {accuracy * 100:.2f}%\")\n","\n","        # Print original and predicted composition for test set\n","        print(\"\\nTest Results (Original vs Predicted):\")\n","        for i in range(len(y_test)):\n","            original = [periodic_table_elements[idx] for idx, val in enumerate(y_test[i]) if val == 1]\n","            predicted = [periodic_table_elements[idx] for idx, val in enumerate(y_pred[i]) if val == 1]\n","            print(f\"Original: {original} | Predicted: {predicted}\")\n","        print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# Main function to run the process\n","def main():\n","    input_file = 'filtered_allData_result.json'\n","\n","    # List of valid periodic table elements (assuming the same as in previous code)\n","    periodic_table_elements = [\n","        \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\",\n","        \"Cl\", \"Ar\", \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"Ga\",\n","        \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\",\n","        \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\", \"Pm\",\n","        \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\",\n","        \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\", \"Pa\",\n","        \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\", \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\",\n","        \"Bh\", \"Hs\", \"Mt\", \"Ds\", \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n","    ]\n","\n","    # Load and preprocess data\n","    data = load_data(input_file)\n","    features, compositions = preprocess_data(data, periodic_table_elements)\n","\n","    # Encode features into a numeric format\n","    X = encode_features(features)\n","    y = np.array(compositions)\n","\n","    # Train and evaluate models\n","    train_and_evaluate(X, y, periodic_table_elements)\n","\n","# Run the script\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"markdown","source":["#MLP"],"metadata":{"id":"Ck3lJw13FanS"}},{"cell_type":"code","source":["import json\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Load filtered JSON data\n","def load_data(input_file):\n","    with open(input_file, 'r') as infile:\n","        data = json.load(infile)\n","    return data\n","\n","# Preprocessing the data\n","def preprocess_data(data, periodic_table_elements):\n","    compositions = []\n","    features = []\n","\n","    # Extract features and compositions\n","    for entry in data:\n","        features.append(entry['lemma'])\n","        composition = [1 if elem in entry['composition'] else 0 for elem in periodic_table_elements]\n","        compositions.append(composition)\n","\n","    return features, compositions\n","\n","# Encode the feature list into a one-hot encoding format\n","def encode_features(feature_list):\n","    df = pd.DataFrame(feature_list)\n","    df_encoded = pd.get_dummies(df, prefix_sep='_', drop_first=True)\n","    return df_encoded\n","\n","# Define and compile the MLP model\n","def create_mlp(input_dim, output_dim):\n","    model = Sequential([\n","        Dense(128, input_dim=input_dim, activation='relu'),\n","        Dense(64, activation='relu'),\n","        Dense(32, activation='relu'),\n","        Dense(output_dim, activation='sigmoid')  # Sigmoid for multi-label classification\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Train and evaluate MLP model with overall accuracy calculation\n","def train_and_evaluate_mlp(X_train, X_test, y_train, y_test, periodic_table_elements):\n","    input_dim = X_train.shape[1]\n","    output_dim = y_train.shape[1]\n","\n","    model = create_mlp(input_dim, output_dim)\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","    history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32,\n","                        callbacks=[early_stopping], verbose=2)\n","\n","    # Evaluate on test data\n","    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","    print(f\"\\nMLP Test Accuracy per label: {test_accuracy * 100:.2f}%\")\n","\n","    # Predict on test set\n","    y_pred = model.predict(X_test)\n","    y_pred = (y_pred > 0.5).astype(int)\n","\n","    # Calculate and print overall accuracy\n","    overall_accuracy = np.mean([np.array_equal(y_test[i], y_pred[i]) for i in range(len(y_test))])\n","    print(f\"\\nOverall MLP Accuracy: {overall_accuracy * 100:.2f}%\")\n","\n","    # Print original and predicted composition for test set\n","    print(\"\\nTest Results (Original vs Predicted):\")\n","    for i in range(len(y_test)):\n","        original = [periodic_table_elements[idx] for idx, val in enumerate(y_test[i]) if val == 1]\n","        predicted = [periodic_table_elements[idx] for idx, val in enumerate(y_pred[i]) if val == 1]\n","        print(f\"Original: {original} | Predicted: {predicted}\")\n","    print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# Main function to run the process\n","def main():\n","    input_file = 'filtered_allData_result.json'\n","\n","    # List of valid periodic table elements\n","    periodic_table_elements = [\n","        \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\",\n","        \"Cl\", \"Ar\", \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"Ga\",\n","        \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\",\n","        \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\", \"Pm\",\n","        \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\",\n","        \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\", \"Pa\",\n","        \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\", \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\",\n","        \"Bh\", \"Hs\", \"Mt\", \"Ds\", \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n","    ]\n","\n","    # Load and preprocess data\n","    data = load_data(input_file)\n","    features, compositions = preprocess_data(data, periodic_table_elements)\n","\n","    # Encode features into a numeric format\n","    X = encode_features(features)\n","    y = np.array(compositions)\n","\n","    # Split the data into 80% training and 20% testing\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Feature Scaling\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","    # Train and evaluate MLP model\n","    train_and_evaluate_mlp(X_train, X_test, y_train, y_test, periodic_table_elements)\n","\n","# Run the script\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZonXczKETSj","executionInfo":{"status":"ok","timestamp":1730141938254,"user_tz":300,"elapsed":15807,"user":{"displayName":"Kishan kumar","userId":"12369662999305954818"}},"outputId":"717bdd03-a82d-4445-e68e-a94a8d2b6525"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 - 2s - 2s/step - accuracy: 0.0000e+00 - loss: 0.6943 - val_accuracy: 0.0000e+00 - val_loss: 0.6806\n","Epoch 2/100\n","1/1 - 0s - 319ms/step - accuracy: 0.0000e+00 - loss: 0.6809 - val_accuracy: 0.0000e+00 - val_loss: 0.6719\n","Epoch 3/100\n","1/1 - 0s - 77ms/step - accuracy: 0.0000e+00 - loss: 0.6689 - val_accuracy: 0.0000e+00 - val_loss: 0.6633\n","Epoch 4/100\n","1/1 - 0s - 56ms/step - accuracy: 0.0000e+00 - loss: 0.6579 - val_accuracy: 0.0000e+00 - val_loss: 0.6542\n","Epoch 5/100\n","1/1 - 0s - 76ms/step - accuracy: 0.0000e+00 - loss: 0.6468 - val_accuracy: 0.0000e+00 - val_loss: 0.6447\n","Epoch 6/100\n","1/1 - 0s - 64ms/step - accuracy: 0.0000e+00 - loss: 0.6351 - val_accuracy: 0.0000e+00 - val_loss: 0.6346\n","Epoch 7/100\n","1/1 - 0s - 58ms/step - accuracy: 0.0000e+00 - loss: 0.6228 - val_accuracy: 0.0000e+00 - val_loss: 0.6238\n","Epoch 8/100\n","1/1 - 0s - 55ms/step - accuracy: 0.0000e+00 - loss: 0.6097 - val_accuracy: 0.0000e+00 - val_loss: 0.6123\n","Epoch 9/100\n","1/1 - 0s - 59ms/step - accuracy: 0.0000e+00 - loss: 0.5957 - val_accuracy: 0.0000e+00 - val_loss: 0.5999\n","Epoch 10/100\n","1/1 - 0s - 60ms/step - accuracy: 0.0000e+00 - loss: 0.5805 - val_accuracy: 0.0000e+00 - val_loss: 0.5867\n","Epoch 11/100\n","1/1 - 0s - 57ms/step - accuracy: 0.0000e+00 - loss: 0.5642 - val_accuracy: 0.0000e+00 - val_loss: 0.5726\n","Epoch 12/100\n","1/1 - 0s - 60ms/step - accuracy: 0.0000e+00 - loss: 0.5469 - val_accuracy: 0.0000e+00 - val_loss: 0.5577\n","Epoch 13/100\n","1/1 - 0s - 55ms/step - accuracy: 0.0000e+00 - loss: 0.5285 - val_accuracy: 0.0000e+00 - val_loss: 0.5417\n","Epoch 14/100\n","1/1 - 0s - 59ms/step - accuracy: 0.0000e+00 - loss: 0.5089 - val_accuracy: 0.0000e+00 - val_loss: 0.5248\n","Epoch 15/100\n","1/1 - 0s - 139ms/step - accuracy: 0.0000e+00 - loss: 0.4883 - val_accuracy: 0.0000e+00 - val_loss: 0.5071\n","Epoch 16/100\n","1/1 - 0s - 70ms/step - accuracy: 0.0000e+00 - loss: 0.4668 - val_accuracy: 0.0000e+00 - val_loss: 0.4886\n","Epoch 17/100\n","1/1 - 0s - 70ms/step - accuracy: 0.0000e+00 - loss: 0.4446 - val_accuracy: 0.0000e+00 - val_loss: 0.4696\n","Epoch 18/100\n","1/1 - 0s - 64ms/step - accuracy: 0.0000e+00 - loss: 0.4218 - val_accuracy: 0.0000e+00 - val_loss: 0.4500\n","Epoch 19/100\n","1/1 - 0s - 137ms/step - accuracy: 0.0000e+00 - loss: 0.3987 - val_accuracy: 0.0000e+00 - val_loss: 0.4300\n","Epoch 20/100\n","1/1 - 0s - 56ms/step - accuracy: 0.0000e+00 - loss: 0.3752 - val_accuracy: 0.0000e+00 - val_loss: 0.4096\n","Epoch 21/100\n","1/1 - 0s - 58ms/step - accuracy: 0.0000e+00 - loss: 0.3517 - val_accuracy: 0.0000e+00 - val_loss: 0.3891\n","Epoch 22/100\n","1/1 - 0s - 57ms/step - accuracy: 0.0000e+00 - loss: 0.3283 - val_accuracy: 0.0000e+00 - val_loss: 0.3687\n","Epoch 23/100\n","1/1 - 0s - 56ms/step - accuracy: 0.0000e+00 - loss: 0.3054 - val_accuracy: 0.0000e+00 - val_loss: 0.3487\n","Epoch 24/100\n","1/1 - 0s - 61ms/step - accuracy: 0.0000e+00 - loss: 0.2831 - val_accuracy: 0.0000e+00 - val_loss: 0.3293\n","Epoch 25/100\n","1/1 - 0s - 58ms/step - accuracy: 0.0000e+00 - loss: 0.2616 - val_accuracy: 0.0000e+00 - val_loss: 0.3106\n","Epoch 26/100\n","1/1 - 0s - 74ms/step - accuracy: 0.0000e+00 - loss: 0.2410 - val_accuracy: 0.0000e+00 - val_loss: 0.2926\n","Epoch 27/100\n","1/1 - 0s - 56ms/step - accuracy: 0.0625 - loss: 0.2215 - val_accuracy: 0.0000e+00 - val_loss: 0.2759\n","Epoch 28/100\n","1/1 - 0s - 59ms/step - accuracy: 0.0625 - loss: 0.2033 - val_accuracy: 0.0000e+00 - val_loss: 0.2601\n","Epoch 29/100\n","1/1 - 0s - 60ms/step - accuracy: 0.0625 - loss: 0.1862 - val_accuracy: 0.0000e+00 - val_loss: 0.2455\n","Epoch 30/100\n","1/1 - 0s - 148ms/step - accuracy: 0.0625 - loss: 0.1704 - val_accuracy: 0.0000e+00 - val_loss: 0.2320\n","Epoch 31/100\n","1/1 - 0s - 137ms/step - accuracy: 0.0625 - loss: 0.1557 - val_accuracy: 0.0000e+00 - val_loss: 0.2198\n","Epoch 32/100\n","1/1 - 0s - 128ms/step - accuracy: 0.0625 - loss: 0.1424 - val_accuracy: 0.0000e+00 - val_loss: 0.2087\n","Epoch 33/100\n","1/1 - 0s - 56ms/step - accuracy: 0.0000e+00 - loss: 0.1301 - val_accuracy: 0.0000e+00 - val_loss: 0.1989\n","Epoch 34/100\n","1/1 - 0s - 56ms/step - accuracy: 0.0000e+00 - loss: 0.1190 - val_accuracy: 0.0000e+00 - val_loss: 0.1901\n","Epoch 35/100\n","1/1 - 0s - 77ms/step - accuracy: 0.0000e+00 - loss: 0.1091 - val_accuracy: 0.0000e+00 - val_loss: 0.1823\n","Epoch 36/100\n","1/1 - 0s - 51ms/step - accuracy: 0.0000e+00 - loss: 0.1004 - val_accuracy: 0.0000e+00 - val_loss: 0.1753\n","Epoch 37/100\n","1/1 - 0s - 57ms/step - accuracy: 0.0000e+00 - loss: 0.0927 - val_accuracy: 0.0000e+00 - val_loss: 0.1690\n","Epoch 38/100\n","1/1 - 0s - 57ms/step - accuracy: 0.0000e+00 - loss: 0.0861 - val_accuracy: 0.0000e+00 - val_loss: 0.1635\n","Epoch 39/100\n","1/1 - 0s - 51ms/step - accuracy: 0.0000e+00 - loss: 0.0804 - val_accuracy: 0.0000e+00 - val_loss: 0.1587\n","Epoch 40/100\n","1/1 - 0s - 71ms/step - accuracy: 0.0000e+00 - loss: 0.0753 - val_accuracy: 0.0000e+00 - val_loss: 0.1546\n","Epoch 41/100\n","1/1 - 0s - 124ms/step - accuracy: 0.0000e+00 - loss: 0.0709 - val_accuracy: 0.0000e+00 - val_loss: 0.1510\n","Epoch 42/100\n","1/1 - 0s - 58ms/step - accuracy: 0.0000e+00 - loss: 0.0670 - val_accuracy: 0.0000e+00 - val_loss: 0.1479\n","Epoch 43/100\n","1/1 - 0s - 69ms/step - accuracy: 0.1250 - loss: 0.0636 - val_accuracy: 0.0000e+00 - val_loss: 0.1453\n","Epoch 44/100\n","1/1 - 0s - 62ms/step - accuracy: 0.1875 - loss: 0.0606 - val_accuracy: 0.0000e+00 - val_loss: 0.1431\n","Epoch 45/100\n","1/1 - 0s - 52ms/step - accuracy: 0.1875 - loss: 0.0580 - val_accuracy: 0.0000e+00 - val_loss: 0.1411\n","Epoch 46/100\n","1/1 - 0s - 52ms/step - accuracy: 0.1875 - loss: 0.0557 - val_accuracy: 0.0000e+00 - val_loss: 0.1393\n","Epoch 47/100\n","1/1 - 0s - 53ms/step - accuracy: 0.1875 - loss: 0.0535 - val_accuracy: 0.0000e+00 - val_loss: 0.1377\n","Epoch 48/100\n","1/1 - 0s - 58ms/step - accuracy: 0.1875 - loss: 0.0515 - val_accuracy: 0.0000e+00 - val_loss: 0.1361\n","Epoch 49/100\n","1/1 - 0s - 84ms/step - accuracy: 0.1875 - loss: 0.0495 - val_accuracy: 0.0000e+00 - val_loss: 0.1346\n","Epoch 50/100\n","1/1 - 0s - 96ms/step - accuracy: 0.2500 - loss: 0.0475 - val_accuracy: 0.2000 - val_loss: 0.1331\n","Epoch 51/100\n","1/1 - 0s - 128ms/step - accuracy: 0.3750 - loss: 0.0455 - val_accuracy: 0.2000 - val_loss: 0.1316\n","Epoch 52/100\n","1/1 - 0s - 99ms/step - accuracy: 0.3750 - loss: 0.0436 - val_accuracy: 0.2000 - val_loss: 0.1301\n","Epoch 53/100\n","1/1 - 0s - 133ms/step - accuracy: 0.3750 - loss: 0.0418 - val_accuracy: 0.2000 - val_loss: 0.1287\n","Epoch 54/100\n","1/1 - 0s - 144ms/step - accuracy: 0.3750 - loss: 0.0400 - val_accuracy: 0.2000 - val_loss: 0.1272\n","Epoch 55/100\n","1/1 - 0s - 108ms/step - accuracy: 0.3750 - loss: 0.0383 - val_accuracy: 0.2000 - val_loss: 0.1259\n","Epoch 56/100\n","1/1 - 0s - 132ms/step - accuracy: 0.3750 - loss: 0.0368 - val_accuracy: 0.0000e+00 - val_loss: 0.1247\n","Epoch 57/100\n","1/1 - 0s - 86ms/step - accuracy: 0.1875 - loss: 0.0354 - val_accuracy: 0.0000e+00 - val_loss: 0.1236\n","Epoch 58/100\n","1/1 - 0s - 138ms/step - accuracy: 0.1875 - loss: 0.0340 - val_accuracy: 0.0000e+00 - val_loss: 0.1226\n","Epoch 59/100\n","1/1 - 0s - 153ms/step - accuracy: 0.1875 - loss: 0.0327 - val_accuracy: 0.0000e+00 - val_loss: 0.1216\n","Epoch 60/100\n","1/1 - 0s - 110ms/step - accuracy: 0.1250 - loss: 0.0314 - val_accuracy: 0.0000e+00 - val_loss: 0.1207\n","Epoch 61/100\n","1/1 - 0s - 140ms/step - accuracy: 0.1250 - loss: 0.0302 - val_accuracy: 0.0000e+00 - val_loss: 0.1197\n","Epoch 62/100\n","1/1 - 0s - 132ms/step - accuracy: 0.1250 - loss: 0.0291 - val_accuracy: 0.0000e+00 - val_loss: 0.1188\n","Epoch 63/100\n","1/1 - 0s - 97ms/step - accuracy: 0.1250 - loss: 0.0279 - val_accuracy: 0.0000e+00 - val_loss: 0.1178\n","Epoch 64/100\n","1/1 - 0s - 95ms/step - accuracy: 0.1250 - loss: 0.0268 - val_accuracy: 0.0000e+00 - val_loss: 0.1169\n","Epoch 65/100\n","1/1 - 0s - 95ms/step - accuracy: 0.1875 - loss: 0.0256 - val_accuracy: 0.0000e+00 - val_loss: 0.1160\n","Epoch 66/100\n","1/1 - 0s - 143ms/step - accuracy: 0.1875 - loss: 0.0245 - val_accuracy: 0.0000e+00 - val_loss: 0.1151\n","Epoch 67/100\n","1/1 - 0s - 89ms/step - accuracy: 0.1875 - loss: 0.0233 - val_accuracy: 0.0000e+00 - val_loss: 0.1143\n","Epoch 68/100\n","1/1 - 0s - 156ms/step - accuracy: 0.1875 - loss: 0.0222 - val_accuracy: 0.0000e+00 - val_loss: 0.1135\n","Epoch 69/100\n","1/1 - 0s - 143ms/step - accuracy: 0.1875 - loss: 0.0211 - val_accuracy: 0.2000 - val_loss: 0.1128\n","Epoch 70/100\n","1/1 - 0s - 128ms/step - accuracy: 0.1875 - loss: 0.0200 - val_accuracy: 0.2000 - val_loss: 0.1121\n","Epoch 71/100\n","1/1 - 0s - 134ms/step - accuracy: 0.1250 - loss: 0.0189 - val_accuracy: 0.2000 - val_loss: 0.1114\n","Epoch 72/100\n","1/1 - 0s - 105ms/step - accuracy: 0.1250 - loss: 0.0180 - val_accuracy: 0.2000 - val_loss: 0.1108\n","Epoch 73/100\n","1/1 - 0s - 122ms/step - accuracy: 0.1250 - loss: 0.0170 - val_accuracy: 0.2000 - val_loss: 0.1103\n","Epoch 74/100\n","1/1 - 0s - 90ms/step - accuracy: 0.1250 - loss: 0.0161 - val_accuracy: 0.2000 - val_loss: 0.1098\n","Epoch 75/100\n","1/1 - 0s - 94ms/step - accuracy: 0.1250 - loss: 0.0153 - val_accuracy: 0.2000 - val_loss: 0.1094\n","Epoch 76/100\n","1/1 - 0s - 94ms/step - accuracy: 0.1250 - loss: 0.0144 - val_accuracy: 0.2000 - val_loss: 0.1090\n","Epoch 77/100\n","1/1 - 0s - 98ms/step - accuracy: 0.1250 - loss: 0.0137 - val_accuracy: 0.2000 - val_loss: 0.1086\n","Epoch 78/100\n","1/1 - 0s - 125ms/step - accuracy: 0.1250 - loss: 0.0129 - val_accuracy: 0.2000 - val_loss: 0.1082\n","Epoch 79/100\n","1/1 - 0s - 56ms/step - accuracy: 0.1875 - loss: 0.0122 - val_accuracy: 0.2000 - val_loss: 0.1079\n","Epoch 80/100\n","1/1 - 0s - 134ms/step - accuracy: 0.1875 - loss: 0.0116 - val_accuracy: 0.2000 - val_loss: 0.1076\n","Epoch 81/100\n","1/1 - 0s - 56ms/step - accuracy: 0.1875 - loss: 0.0109 - val_accuracy: 0.2000 - val_loss: 0.1073\n","Epoch 82/100\n","1/1 - 0s - 138ms/step - accuracy: 0.1875 - loss: 0.0103 - val_accuracy: 0.2000 - val_loss: 0.1071\n","Epoch 83/100\n","1/1 - 0s - 54ms/step - accuracy: 0.3125 - loss: 0.0098 - val_accuracy: 0.2000 - val_loss: 0.1069\n","Epoch 84/100\n","1/1 - 0s - 56ms/step - accuracy: 0.3125 - loss: 0.0093 - val_accuracy: 0.2000 - val_loss: 0.1067\n","Epoch 85/100\n","1/1 - 0s - 57ms/step - accuracy: 0.3125 - loss: 0.0088 - val_accuracy: 0.2000 - val_loss: 0.1065\n","Epoch 86/100\n","1/1 - 0s - 57ms/step - accuracy: 0.2500 - loss: 0.0083 - val_accuracy: 0.2000 - val_loss: 0.1063\n","Epoch 87/100\n","1/1 - 0s - 52ms/step - accuracy: 0.2500 - loss: 0.0079 - val_accuracy: 0.2000 - val_loss: 0.1062\n","Epoch 88/100\n","1/1 - 0s - 59ms/step - accuracy: 0.2500 - loss: 0.0075 - val_accuracy: 0.2000 - val_loss: 0.1060\n","Epoch 89/100\n","1/1 - 0s - 60ms/step - accuracy: 0.2500 - loss: 0.0071 - val_accuracy: 0.2000 - val_loss: 0.1059\n","Epoch 90/100\n","1/1 - 0s - 61ms/step - accuracy: 0.2500 - loss: 0.0067 - val_accuracy: 0.2000 - val_loss: 0.1058\n","Epoch 91/100\n","1/1 - 0s - 132ms/step - accuracy: 0.2500 - loss: 0.0064 - val_accuracy: 0.2000 - val_loss: 0.1057\n","Epoch 92/100\n","1/1 - 0s - 68ms/step - accuracy: 0.2500 - loss: 0.0061 - val_accuracy: 0.2000 - val_loss: 0.1056\n","Epoch 93/100\n","1/1 - 0s - 52ms/step - accuracy: 0.2500 - loss: 0.0058 - val_accuracy: 0.2000 - val_loss: 0.1055\n","Epoch 94/100\n","1/1 - 0s - 60ms/step - accuracy: 0.2500 - loss: 0.0055 - val_accuracy: 0.2000 - val_loss: 0.1054\n","Epoch 95/100\n","1/1 - 0s - 51ms/step - accuracy: 0.2500 - loss: 0.0052 - val_accuracy: 0.2000 - val_loss: 0.1053\n","Epoch 96/100\n","1/1 - 0s - 57ms/step - accuracy: 0.2500 - loss: 0.0050 - val_accuracy: 0.2000 - val_loss: 0.1052\n","Epoch 97/100\n","1/1 - 0s - 65ms/step - accuracy: 0.2500 - loss: 0.0047 - val_accuracy: 0.2000 - val_loss: 0.1050\n","Epoch 98/100\n","1/1 - 0s - 132ms/step - accuracy: 0.2500 - loss: 0.0045 - val_accuracy: 0.2000 - val_loss: 0.1049\n","Epoch 99/100\n","1/1 - 0s - 66ms/step - accuracy: 0.2500 - loss: 0.0043 - val_accuracy: 0.2000 - val_loss: 0.1047\n","Epoch 100/100\n","1/1 - 0s - 55ms/step - accuracy: 0.2500 - loss: 0.0041 - val_accuracy: 0.2000 - val_loss: 0.1046\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.0716\n","\n","MLP Test Accuracy per label: 0.00%\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n","\n","Overall MLP Accuracy: 33.33%\n","\n","Test Results (Original vs Predicted):\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['H', 'Si', 'Cr', 'Mn', 'Fe', 'Co'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Cu', 'Zn'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Si', 'Cr', 'Mn', 'Fe', 'Co', 'Cu'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Cu']\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","\n","==================================================\n","\n"]}]},{"cell_type":"code","source":["import json\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","# Load filtered JSON data\n","def load_data(input_file):\n","    with open(input_file, 'r') as infile:\n","        data = json.load(infile)\n","    return data\n","\n","# Preprocessing the data\n","def preprocess_data(data, periodic_table_elements):\n","    compositions = []\n","    features = []\n","\n","    # Extract features and compositions\n","    for entry in data:\n","        features.append(entry['lemma'])\n","        composition = [1 if elem in entry['composition'] else 0 for elem in periodic_table_elements]\n","        compositions.append(composition)\n","\n","    return features, compositions\n","\n","# Encode the feature list into a one-hot encoding format\n","def encode_features(feature_list):\n","    df = pd.DataFrame(feature_list)\n","    df_encoded = pd.get_dummies(df, prefix_sep='_', drop_first=True)\n","    return df_encoded\n","\n","# Define and compile the enhanced MLP model\n","def create_mlp(input_dim, output_dim):\n","    model = Sequential([\n","        Dense(256, input_dim=input_dim, activation='relu'),\n","        Dropout(0.3),  # Dropout layer to prevent overfitting\n","        Dense(128, activation='relu'),\n","        Dropout(0.3),\n","        Dense(64, activation='relu'),\n","        Dense(output_dim, activation='sigmoid')  # Sigmoid for multi-label classification\n","    ])\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Train and evaluate MLP model with overall accuracy calculation\n","def train_and_evaluate_mlp(X_train, X_test, y_train, y_test, periodic_table_elements):\n","    input_dim = X_train.shape[1]\n","    output_dim = y_train.shape[1]\n","\n","    model = create_mlp(input_dim, output_dim)\n","\n","    # Early stopping and adaptive learning rate reduction\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n","\n","    # Train the model\n","    history = model.fit(X_train, y_train, validation_split=0.2, epochs=150, batch_size=64,\n","                        callbacks=[early_stopping, reduce_lr], verbose=2)\n","\n","    # Evaluate on test data\n","    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","    print(f\"\\nMLP Test Accuracy per label: {test_accuracy * 100:.2f}%\")\n","\n","    # Predict on test set\n","    y_pred = model.predict(X_test)\n","    y_pred = (y_pred > 0.5).astype(int)\n","\n","    # Calculate and print overall accuracy\n","    overall_accuracy = np.mean([np.array_equal(y_test[i], y_pred[i]) for i in range(len(y_test))])\n","    print(f\"\\nOverall MLP Accuracy: {overall_accuracy * 100:.2f}%\")\n","\n","    # Print original and predicted composition for test set\n","    print(\"\\nTest Results (Original vs Predicted):\")\n","    for i in range(len(y_test)):\n","        original = [periodic_table_elements[idx] for idx, val in enumerate(y_test[i]) if val == 1]\n","        predicted = [periodic_table_elements[idx] for idx, val in enumerate(y_pred[i]) if val == 1]\n","        print(f\"Original: {original} | Predicted: {predicted}\")\n","    print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# Main function to run the process\n","def main():\n","    input_file = 'filtered_allData_result.json'\n","\n","    # List of valid periodic table elements\n","    periodic_table_elements = [\n","        \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\",\n","        \"Cl\", \"Ar\", \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"Ga\",\n","        \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\",\n","        \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\", \"Pm\",\n","        \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\",\n","        \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\", \"Pa\",\n","        \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\", \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\",\n","        \"Bh\", \"Hs\", \"Mt\", \"Ds\", \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n","    ]\n","\n","    # Load and preprocess data\n","    data = load_data(input_file)\n","    features, compositions = preprocess_data(data, periodic_table_elements)\n","\n","    # Encode features into a numeric format\n","    X = encode_features(features)\n","    y = np.array(compositions)\n","\n","    # Split the data into 80% training and 20% testing\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Feature Scaling\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","    # Train and evaluate MLP model\n","    train_and_evaluate_mlp(X_train, X_test, y_train, y_test, periodic_table_elements)\n","\n","# Run the script\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeqEiLzPFcJD","executionInfo":{"status":"ok","timestamp":1730141947251,"user_tz":300,"elapsed":9001,"user":{"displayName":"Kishan kumar","userId":"12369662999305954818"}},"outputId":"55bef1b2-3678-4320-b49d-82146991fae3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 - 2s - 2s/step - accuracy: 0.0000e+00 - loss: 0.7342 - val_accuracy: 0.0000e+00 - val_loss: 0.6928 - learning_rate: 0.0010\n","Epoch 2/150\n","1/1 - 0s - 119ms/step - accuracy: 0.0000e+00 - loss: 0.7048 - val_accuracy: 0.0000e+00 - val_loss: 0.6765 - learning_rate: 0.0010\n","Epoch 3/150\n","1/1 - 0s - 55ms/step - accuracy: 0.0000e+00 - loss: 0.6862 - val_accuracy: 0.0000e+00 - val_loss: 0.6616 - learning_rate: 0.0010\n","Epoch 4/150\n","1/1 - 0s - 58ms/step - accuracy: 0.0000e+00 - loss: 0.6673 - val_accuracy: 0.2000 - val_loss: 0.6468 - learning_rate: 0.0010\n","Epoch 5/150\n","1/1 - 0s - 57ms/step - accuracy: 0.0000e+00 - loss: 0.6476 - val_accuracy: 0.2000 - val_loss: 0.6311 - learning_rate: 0.0010\n","Epoch 6/150\n","1/1 - 0s - 51ms/step - accuracy: 0.0000e+00 - loss: 0.6324 - val_accuracy: 0.2000 - val_loss: 0.6146 - learning_rate: 0.0010\n","Epoch 7/150\n","1/1 - 0s - 54ms/step - accuracy: 0.0625 - loss: 0.6175 - val_accuracy: 0.2000 - val_loss: 0.5962 - learning_rate: 0.0010\n","Epoch 8/150\n","1/1 - 0s - 56ms/step - accuracy: 0.0000e+00 - loss: 0.5972 - val_accuracy: 0.2000 - val_loss: 0.5760 - learning_rate: 0.0010\n","Epoch 9/150\n","1/1 - 0s - 56ms/step - accuracy: 0.0625 - loss: 0.5801 - val_accuracy: 0.2000 - val_loss: 0.5544 - learning_rate: 0.0010\n","Epoch 10/150\n","1/1 - 0s - 51ms/step - accuracy: 0.0625 - loss: 0.5572 - val_accuracy: 0.0000e+00 - val_loss: 0.5313 - learning_rate: 0.0010\n","Epoch 11/150\n","1/1 - 0s - 57ms/step - accuracy: 0.0000e+00 - loss: 0.5254 - val_accuracy: 0.0000e+00 - val_loss: 0.5066 - learning_rate: 0.0010\n","Epoch 12/150\n","1/1 - 0s - 57ms/step - accuracy: 0.0000e+00 - loss: 0.5035 - val_accuracy: 0.0000e+00 - val_loss: 0.4807 - learning_rate: 0.0010\n","Epoch 13/150\n","1/1 - 0s - 55ms/step - accuracy: 0.0000e+00 - loss: 0.4718 - val_accuracy: 0.0000e+00 - val_loss: 0.4534 - learning_rate: 0.0010\n","Epoch 14/150\n","1/1 - 0s - 55ms/step - accuracy: 0.0000e+00 - loss: 0.4451 - val_accuracy: 0.0000e+00 - val_loss: 0.4256 - learning_rate: 0.0010\n","Epoch 15/150\n","1/1 - 0s - 149ms/step - accuracy: 0.0000e+00 - loss: 0.4152 - val_accuracy: 0.0000e+00 - val_loss: 0.3968 - learning_rate: 0.0010\n","Epoch 16/150\n","1/1 - 0s - 125ms/step - accuracy: 0.0000e+00 - loss: 0.3831 - val_accuracy: 0.0000e+00 - val_loss: 0.3676 - learning_rate: 0.0010\n","Epoch 17/150\n","1/1 - 0s - 53ms/step - accuracy: 0.0000e+00 - loss: 0.3560 - val_accuracy: 0.0000e+00 - val_loss: 0.3382 - learning_rate: 0.0010\n","Epoch 18/150\n","1/1 - 0s - 134ms/step - accuracy: 0.0000e+00 - loss: 0.3323 - val_accuracy: 0.0000e+00 - val_loss: 0.3094 - learning_rate: 0.0010\n","Epoch 19/150\n","1/1 - 0s - 56ms/step - accuracy: 0.0000e+00 - loss: 0.2944 - val_accuracy: 0.0000e+00 - val_loss: 0.2817 - learning_rate: 0.0010\n","Epoch 20/150\n","1/1 - 0s - 50ms/step - accuracy: 0.0000e+00 - loss: 0.2766 - val_accuracy: 0.0000e+00 - val_loss: 0.2544 - learning_rate: 0.0010\n","Epoch 21/150\n","1/1 - 0s - 62ms/step - accuracy: 0.0000e+00 - loss: 0.2433 - val_accuracy: 0.0000e+00 - val_loss: 0.2286 - learning_rate: 0.0010\n","Epoch 22/150\n","1/1 - 0s - 139ms/step - accuracy: 0.0000e+00 - loss: 0.2136 - val_accuracy: 0.0000e+00 - val_loss: 0.2046 - learning_rate: 0.0010\n","Epoch 23/150\n","1/1 - 0s - 141ms/step - accuracy: 0.0000e+00 - loss: 0.1921 - val_accuracy: 0.0000e+00 - val_loss: 0.1824 - learning_rate: 0.0010\n","Epoch 24/150\n","1/1 - 0s - 93ms/step - accuracy: 0.0000e+00 - loss: 0.1779 - val_accuracy: 0.0000e+00 - val_loss: 0.1625 - learning_rate: 0.0010\n","Epoch 25/150\n","1/1 - 0s - 69ms/step - accuracy: 0.0000e+00 - loss: 0.1531 - val_accuracy: 0.0000e+00 - val_loss: 0.1450 - learning_rate: 0.0010\n","Epoch 26/150\n","1/1 - 0s - 60ms/step - accuracy: 0.0000e+00 - loss: 0.1389 - val_accuracy: 0.0000e+00 - val_loss: 0.1301 - learning_rate: 0.0010\n","Epoch 27/150\n","1/1 - 0s - 67ms/step - accuracy: 0.0000e+00 - loss: 0.1194 - val_accuracy: 0.0000e+00 - val_loss: 0.1176 - learning_rate: 0.0010\n","Epoch 28/150\n","1/1 - 0s - 61ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1074 - learning_rate: 0.0010\n","Epoch 29/150\n","1/1 - 0s - 78ms/step - accuracy: 0.0000e+00 - loss: 0.0965 - val_accuracy: 0.0000e+00 - val_loss: 0.0995 - learning_rate: 0.0010\n","Epoch 30/150\n","1/1 - 0s - 62ms/step - accuracy: 0.0000e+00 - loss: 0.0848 - val_accuracy: 0.2000 - val_loss: 0.0934 - learning_rate: 0.0010\n","Epoch 31/150\n","1/1 - 0s - 63ms/step - accuracy: 0.0625 - loss: 0.0805 - val_accuracy: 0.2000 - val_loss: 0.0889 - learning_rate: 0.0010\n","Epoch 32/150\n","1/1 - 0s - 137ms/step - accuracy: 0.0000e+00 - loss: 0.0750 - val_accuracy: 0.2000 - val_loss: 0.0857 - learning_rate: 0.0010\n","Epoch 33/150\n","1/1 - 0s - 57ms/step - accuracy: 0.0625 - loss: 0.0721 - val_accuracy: 0.2000 - val_loss: 0.0833 - learning_rate: 0.0010\n","Epoch 34/150\n","1/1 - 0s - 53ms/step - accuracy: 0.1250 - loss: 0.0647 - val_accuracy: 0.4000 - val_loss: 0.0814 - learning_rate: 0.0010\n","Epoch 35/150\n","1/1 - 0s - 53ms/step - accuracy: 0.0625 - loss: 0.0692 - val_accuracy: 0.4000 - val_loss: 0.0795 - learning_rate: 0.0010\n","Epoch 36/150\n","1/1 - 0s - 57ms/step - accuracy: 0.0000e+00 - loss: 0.0590 - val_accuracy: 0.4000 - val_loss: 0.0775 - learning_rate: 0.0010\n","Epoch 37/150\n","1/1 - 0s - 61ms/step - accuracy: 0.2500 - loss: 0.0560 - val_accuracy: 0.4000 - val_loss: 0.0756 - learning_rate: 0.0010\n","Epoch 38/150\n","1/1 - 0s - 131ms/step - accuracy: 0.3750 - loss: 0.0552 - val_accuracy: 0.2000 - val_loss: 0.0734 - learning_rate: 0.0010\n","Epoch 39/150\n","1/1 - 0s - 53ms/step - accuracy: 0.0625 - loss: 0.0513 - val_accuracy: 0.2000 - val_loss: 0.0714 - learning_rate: 0.0010\n","Epoch 40/150\n","1/1 - 0s - 52ms/step - accuracy: 0.1250 - loss: 0.0495 - val_accuracy: 0.2000 - val_loss: 0.0694 - learning_rate: 0.0010\n","Epoch 41/150\n","1/1 - 0s - 57ms/step - accuracy: 0.0625 - loss: 0.0477 - val_accuracy: 0.2000 - val_loss: 0.0676 - learning_rate: 0.0010\n","Epoch 42/150\n","1/1 - 0s - 56ms/step - accuracy: 0.1250 - loss: 0.0430 - val_accuracy: 0.2000 - val_loss: 0.0658 - learning_rate: 0.0010\n","Epoch 43/150\n","1/1 - 0s - 53ms/step - accuracy: 0.1875 - loss: 0.0463 - val_accuracy: 0.2000 - val_loss: 0.0640 - learning_rate: 0.0010\n","Epoch 44/150\n","1/1 - 0s - 61ms/step - accuracy: 0.0625 - loss: 0.0349 - val_accuracy: 0.2000 - val_loss: 0.0621 - learning_rate: 0.0010\n","Epoch 45/150\n","1/1 - 0s - 52ms/step - accuracy: 0.1250 - loss: 0.0422 - val_accuracy: 0.2000 - val_loss: 0.0603 - learning_rate: 0.0010\n","Epoch 46/150\n","1/1 - 0s - 51ms/step - accuracy: 0.0625 - loss: 0.0342 - val_accuracy: 0.2000 - val_loss: 0.0587 - learning_rate: 0.0010\n","Epoch 47/150\n","1/1 - 0s - 55ms/step - accuracy: 0.0625 - loss: 0.0342 - val_accuracy: 0.2000 - val_loss: 0.0573 - learning_rate: 0.0010\n","Epoch 48/150\n","1/1 - 0s - 59ms/step - accuracy: 0.0625 - loss: 0.0317 - val_accuracy: 0.2000 - val_loss: 0.0561 - learning_rate: 0.0010\n","Epoch 49/150\n","1/1 - 0s - 65ms/step - accuracy: 0.1250 - loss: 0.0338 - val_accuracy: 0.4000 - val_loss: 0.0549 - learning_rate: 0.0010\n","Epoch 50/150\n","1/1 - 0s - 60ms/step - accuracy: 0.0625 - loss: 0.0278 - val_accuracy: 0.4000 - val_loss: 0.0540 - learning_rate: 0.0010\n","Epoch 51/150\n","1/1 - 0s - 64ms/step - accuracy: 0.1250 - loss: 0.0309 - val_accuracy: 0.4000 - val_loss: 0.0532 - learning_rate: 0.0010\n","Epoch 52/150\n","1/1 - 0s - 100ms/step - accuracy: 0.0625 - loss: 0.0219 - val_accuracy: 0.4000 - val_loss: 0.0525 - learning_rate: 0.0010\n","Epoch 53/150\n","1/1 - 0s - 73ms/step - accuracy: 0.0625 - loss: 0.0222 - val_accuracy: 0.4000 - val_loss: 0.0518 - learning_rate: 0.0010\n","Epoch 54/150\n","1/1 - 0s - 63ms/step - accuracy: 0.1250 - loss: 0.0248 - val_accuracy: 0.4000 - val_loss: 0.0511 - learning_rate: 0.0010\n","Epoch 55/150\n","1/1 - 0s - 80ms/step - accuracy: 0.0625 - loss: 0.0193 - val_accuracy: 0.4000 - val_loss: 0.0505 - learning_rate: 0.0010\n","Epoch 56/150\n","1/1 - 0s - 96ms/step - accuracy: 0.0625 - loss: 0.0248 - val_accuracy: 0.4000 - val_loss: 0.0501 - learning_rate: 0.0010\n","Epoch 57/150\n","1/1 - 0s - 63ms/step - accuracy: 0.0625 - loss: 0.0245 - val_accuracy: 0.4000 - val_loss: 0.0498 - learning_rate: 0.0010\n","Epoch 58/150\n","1/1 - 0s - 64ms/step - accuracy: 0.1875 - loss: 0.0256 - val_accuracy: 0.4000 - val_loss: 0.0495 - learning_rate: 0.0010\n","Epoch 59/150\n","1/1 - 0s - 138ms/step - accuracy: 0.0625 - loss: 0.0194 - val_accuracy: 0.4000 - val_loss: 0.0492 - learning_rate: 0.0010\n","Epoch 60/150\n","1/1 - 0s - 68ms/step - accuracy: 0.0625 - loss: 0.0174 - val_accuracy: 0.4000 - val_loss: 0.0489 - learning_rate: 0.0010\n","Epoch 61/150\n","1/1 - 0s - 64ms/step - accuracy: 0.1250 - loss: 0.0168 - val_accuracy: 0.4000 - val_loss: 0.0487 - learning_rate: 0.0010\n","Epoch 62/150\n","1/1 - 0s - 63ms/step - accuracy: 0.0625 - loss: 0.0171 - val_accuracy: 0.4000 - val_loss: 0.0486 - learning_rate: 0.0010\n","Epoch 63/150\n","1/1 - 0s - 67ms/step - accuracy: 0.1250 - loss: 0.0127 - val_accuracy: 0.4000 - val_loss: 0.0485 - learning_rate: 0.0010\n","Epoch 64/150\n","1/1 - 0s - 99ms/step - accuracy: 0.1250 - loss: 0.0127 - val_accuracy: 0.4000 - val_loss: 0.0482 - learning_rate: 0.0010\n","Epoch 65/150\n","1/1 - 0s - 102ms/step - accuracy: 0.0625 - loss: 0.0119 - val_accuracy: 0.4000 - val_loss: 0.0479 - learning_rate: 0.0010\n","Epoch 66/150\n","1/1 - 0s - 60ms/step - accuracy: 0.1875 - loss: 0.0103 - val_accuracy: 0.4000 - val_loss: 0.0475 - learning_rate: 0.0010\n","Epoch 67/150\n","1/1 - 0s - 58ms/step - accuracy: 0.1875 - loss: 0.0139 - val_accuracy: 0.4000 - val_loss: 0.0472 - learning_rate: 0.0010\n","Epoch 68/150\n","1/1 - 0s - 57ms/step - accuracy: 0.0625 - loss: 0.0121 - val_accuracy: 0.4000 - val_loss: 0.0468 - learning_rate: 0.0010\n","Epoch 69/150\n","1/1 - 0s - 80ms/step - accuracy: 0.0625 - loss: 0.0105 - val_accuracy: 0.4000 - val_loss: 0.0464 - learning_rate: 0.0010\n","Epoch 70/150\n","1/1 - 0s - 60ms/step - accuracy: 0.1250 - loss: 0.0103 - val_accuracy: 0.4000 - val_loss: 0.0461 - learning_rate: 0.0010\n","Epoch 71/150\n","1/1 - 0s - 62ms/step - accuracy: 0.1250 - loss: 0.0071 - val_accuracy: 0.4000 - val_loss: 0.0458 - learning_rate: 0.0010\n","Epoch 72/150\n","1/1 - 0s - 57ms/step - accuracy: 0.0625 - loss: 0.0103 - val_accuracy: 0.4000 - val_loss: 0.0455 - learning_rate: 0.0010\n","Epoch 73/150\n","1/1 - 0s - 61ms/step - accuracy: 0.1875 - loss: 0.0102 - val_accuracy: 0.4000 - val_loss: 0.0453 - learning_rate: 0.0010\n","Epoch 74/150\n","1/1 - 0s - 53ms/step - accuracy: 0.1250 - loss: 0.0126 - val_accuracy: 0.4000 - val_loss: 0.0451 - learning_rate: 0.0010\n","Epoch 75/150\n","1/1 - 0s - 54ms/step - accuracy: 0.1250 - loss: 0.0047 - val_accuracy: 0.4000 - val_loss: 0.0448 - learning_rate: 0.0010\n","Epoch 76/150\n","1/1 - 0s - 56ms/step - accuracy: 0.1250 - loss: 0.0057 - val_accuracy: 0.4000 - val_loss: 0.0446 - learning_rate: 0.0010\n","Epoch 77/150\n","1/1 - 0s - 67ms/step - accuracy: 0.1250 - loss: 0.0060 - val_accuracy: 0.4000 - val_loss: 0.0444 - learning_rate: 0.0010\n","Epoch 78/150\n","1/1 - 0s - 73ms/step - accuracy: 0.0625 - loss: 0.0077 - val_accuracy: 0.4000 - val_loss: 0.0442 - learning_rate: 0.0010\n","Epoch 79/150\n","1/1 - 0s - 76ms/step - accuracy: 0.1875 - loss: 0.0080 - val_accuracy: 0.4000 - val_loss: 0.0443 - learning_rate: 0.0010\n","Epoch 80/150\n","1/1 - 0s - 78ms/step - accuracy: 0.0625 - loss: 0.0056 - val_accuracy: 0.4000 - val_loss: 0.0445 - learning_rate: 0.0010\n","Epoch 81/150\n","\n","Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","1/1 - 0s - 76ms/step - accuracy: 0.0625 - loss: 0.0060 - val_accuracy: 0.4000 - val_loss: 0.0448 - learning_rate: 0.0010\n","Epoch 82/150\n","1/1 - 0s - 157ms/step - accuracy: 0.0625 - loss: 0.0058 - val_accuracy: 0.4000 - val_loss: 0.0449 - learning_rate: 5.0000e-04\n","Epoch 83/150\n","1/1 - 0s - 80ms/step - accuracy: 0.1250 - loss: 0.0055 - val_accuracy: 0.4000 - val_loss: 0.0449 - learning_rate: 5.0000e-04\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.0759\n","\n","MLP Test Accuracy per label: 0.00%\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n","\n","Overall MLP Accuracy: 50.00%\n","\n","Test Results (Original vs Predicted):\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['H', 'Si', 'Cr', 'Mn', 'Fe', 'Co'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Cu', 'Zn'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Si', 'Cr', 'Mn', 'Fe', 'Co', 'Cu'] | Predicted: ['Si', 'Cr', 'Mn', 'Fe', 'Co', 'Cu']\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","\n","==================================================\n","\n"]}]},{"cell_type":"code","source":["import json\n","import numpy as np\n","import pandas as pd\n","import warnings\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, hamming_loss\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.multiclass import OneVsRestClassifier\n","\n","# Suppress specific warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.multiclass\")\n","\n","# Load filtered JSON data\n","def load_data(input_file):\n","    with open(input_file, 'r') as infile:\n","        data = json.load(infile)\n","    return data\n","\n","# Preprocessing the data\n","def preprocess_data(data, periodic_table_elements):\n","    compositions = []\n","    features = []\n","\n","    # Extract features and compositions\n","    for entry in data:\n","        features.append(entry['lemma'])\n","        composition = [1 if elem in entry['composition'] else 0 for elem in periodic_table_elements]\n","        compositions.append(composition)\n","\n","    return features, compositions\n","\n","# Encode the feature list into a one-hot encoding format\n","def encode_features(feature_list):\n","    df = pd.DataFrame(feature_list)\n","    df_encoded = pd.get_dummies(df, prefix_sep='_', drop_first=True)\n","    return df_encoded\n","\n","# Train and evaluate models with OneVsRestClassifier and Hamming Loss\n","def train_and_evaluate_ensemble(X_train, X_test, y_train, y_test, periodic_table_elements):\n","    # Define individual models\n","    rf_model = OneVsRestClassifier(RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42))\n","    xgb_model = OneVsRestClassifier(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=100, max_depth=10, learning_rate=0.05, random_state=42))\n","\n","    models = {'RandomForest': rf_model, 'XGBoost': xgb_model}\n","\n","    # Train and evaluate each model\n","    for name, model in models.items():\n","        print(f\"\\nTraining {name} model...\\n\")\n","        model.fit(X_train, y_train)\n","\n","        # Predict on test set\n","        y_pred = model.predict(X_test)\n","\n","        # Calculate per-label and overall accuracy, and Hamming Loss\n","        test_accuracy = np.mean([accuracy_score(y_test[:, i], y_pred[:, i]) for i in range(y_test.shape[1])])\n","        overall_accuracy = np.mean([np.array_equal(y_test[i], y_pred[i]) for i in range(len(y_test))])\n","        hamming_loss_score = hamming_loss(y_test, y_pred)\n","\n","        print(f\"\\n{name} Test Accuracy per label: {test_accuracy * 100:.2f}%\")\n","        print(f\"Overall {name} Accuracy: {overall_accuracy * 100:.2f}%\")\n","        print(f\"{name} Hamming Loss: {hamming_loss_score:.4f}\")\n","\n","        # Print original and predicted composition for test set\n","        print(\"\\nTest Results (Original vs Predicted):\")\n","        for i in range(len(y_test)):\n","            original = [periodic_table_elements[idx] for idx, val in enumerate(y_test[i]) if val == 1]\n","            predicted = [periodic_table_elements[idx] for idx, val in enumerate(y_pred[i]) if val == 1]\n","            print(f\"Original: {original} | Predicted: {predicted}\")\n","        print(\"\\n\" + \"=\"*50 + \"\\n\")\n","\n","# Main function to run the process\n","def main():\n","    input_file = 'filtered_allData_result.json'  # Update the path as necessary\n","\n","    # List of valid periodic table elements\n","    periodic_table_elements = [\n","        \"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\",\n","        \"Cl\", \"Ar\", \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"Ga\",\n","        \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\",\n","        \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\", \"Cs\", \"Ba\", \"La\", \"Ce\", \"Pr\", \"Nd\", \"Pm\",\n","        \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\",\n","        \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\", \"Fr\", \"Ra\", \"Ac\", \"Th\", \"Pa\",\n","        \"U\", \"Np\", \"Pu\", \"Am\", \"Cm\", \"Bk\", \"Cf\", \"Es\", \"Fm\", \"Md\", \"No\", \"Lr\", \"Rf\", \"Db\", \"Sg\",\n","        \"Bh\", \"Hs\", \"Mt\", \"Ds\", \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"\n","    ]\n","\n","    # Load and preprocess data\n","    data = load_data(input_file)\n","    features, compositions = preprocess_data(data, periodic_table_elements)\n","\n","    # Encode features into a numeric format\n","    X = encode_features(features)\n","    y = np.array(compositions)\n","\n","    # Split the data into 80% training and 20% testing\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Feature Scaling\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","    # Train and evaluate ensemble model\n","    train_and_evaluate_ensemble(X_train, X_test, y_train, y_test, periodic_table_elements)\n","\n","# Run the script\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTLQ8a3nHptP","executionInfo":{"status":"ok","timestamp":1730141955477,"user_tz":300,"elapsed":8238,"user":{"displayName":"Kishan kumar","userId":"12369662999305954818"}},"outputId":"ef5a9c39-7597-4d46-b612-85187f0b7e05"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training RandomForest model...\n","\n","\n","RandomForest Test Accuracy per label: 98.16%\n","Overall RandomForest Accuracy: 50.00%\n","RandomForest Hamming Loss: 0.0184\n","\n","Test Results (Original vs Predicted):\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['H', 'Si', 'Cr', 'Mn', 'Fe', 'Co'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Cu', 'Zn'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Si', 'Cr', 'Mn', 'Fe', 'Co', 'Cu'] | Predicted: ['Si', 'Cr', 'Mn', 'Fe', 'Co', 'Cu']\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","\n","==================================================\n","\n","\n","Training XGBoost model...\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:14] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:15] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:15] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:15] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:15] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:59:15] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","XGBoost Test Accuracy per label: 97.18%\n","Overall XGBoost Accuracy: 33.33%\n","XGBoost Hamming Loss: 0.0282\n","\n","Test Results (Original vs Predicted):\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['H', 'Si', 'Cr', 'Mn', 'Fe', 'Co'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Al', 'Ti', 'Cr', 'Fe', 'Cu', 'Zn'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","Original: ['Si', 'Cr', 'Mn', 'Fe', 'Co', 'Cu'] | Predicted: ['C']\n","Original: ['Cr', 'Mn', 'Fe', 'Co', 'Ni'] | Predicted: ['Cr', 'Mn', 'Fe', 'Co', 'Ni']\n","\n","==================================================\n","\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzQkRvm1TM6jVxoD8Mfw1D"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}